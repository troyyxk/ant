# ant 代码逐行注释版（核心 6 脚本）

这版是“对照源码逐行读”的学习文档。  
我先覆盖最关键的 6 个脚本（也是你主实验链路的核心）：

1. `experiments/common.py`
2. `experiments/build_triplets.py`
3. `experiments/train_constraint_encoder.py`
4. `experiments/retrieve_then_filter.py`
5. `experiments/eval_retrieval_metrics.py`
6. `experiments/rag_grid_search.py`

---

## 1) `experiments/common.py` 逐行注释

- `L1`：开启延迟类型注解解析，避免前向引用问题。
- `L3-L8`：导入基础库（json、数学、随机、路径、类型等）。
- `L10`：导入 `numpy`，后续向量计算都依赖它。
- `L13`：定位项目根目录（当前文件上两级）。
- `L14-L20`：统一定义项目常用目录常量（data / outputs / reports 等）。
- `L23`：定义“确保目录存在”的函数。
- `L24-L30`：枚举需要存在的目录。
- `L31`：`mkdir(parents=True, exist_ok=True)`，不存在就建，存在不报错。
- `L34`：定义随机种子函数。
- `L35`：设置 Python `random` 种子。
- `L36`：设置 `numpy` 随机种子。
- `L39`：定义写入 JSONL 的函数。
- `L40`：保证目标父目录存在。
- `L41`：以 UTF-8 写文件。
- `L42-L43`：逐行写入字典（每行一个 JSON 对象）。
- `L46`：定义读取 JSONL 的函数。
- `L47`：初始化结果列表。
- `L48`：打开文件读取。
- `L49-L52`：逐行去空白并解析 JSON，加入列表。
- `L53`：返回解析后的行对象列表。
- `L56`：定义余弦相似度函数。
- `L57`：分母是两个向量范数乘积并加极小值防止除零。
- `L58`：返回点积除范数，转成 `float`。
- `L61`：定义 `PairwiseAccuracy` 数据类。
- `L63-L66`：保存总数、正确数、平均间隔、中位间隔。
- `L68`：`accuracy` 属性方法。
- `L70-L72`：空样本返回 0，否则返回正确率。
- `L74`：定义序列化输出方法。
- `L75-L81`：把指标打包成字典（供 json 报告写入）。
- `L84`：定义 pairwise accuracy 计算函数。
- `L85-L86`：正负分数长度必须一致，否则抛错。
- `L87`：计算每个样本 margin（正样本分 - 负样本分）。
- `L88`：统计 margin > 0 的个数。
- `L89-L90`：计算 margin 平均值和中位数（空时为 0）。
- `L91`：返回结构化指标对象。
- `L94`：定义安全浮点函数。
- `L95-L96`：若是 NaN/Inf，替换为 0。
- `L97`：正常时返回 `float(x)`。
- `L100`：定义统一加载 sentence encoder 的函数。
- `L101`：函数内部导入，减少全局加载副作用。
- `L103`：实例化 `SentenceTransformer`。
- `L104`：初始化 tokenizer 变量。
- `L105-L108`：兼容不同模型结构，尝试拿到 tokenizer。
- `L110`：注释说明：本地 causal LM 常缺 `pad_token`。
- `L111`：若 tokenizer 存在但无 pad token，则尝试修复。
- `L112`：取 `eos_token` 作为候选 pad token。
- `L113`：只有 eos 存在时才执行修复。
- `L114`：给 tokenizer 设置 pad token。
- `L115-L116`：若模型上也有 tokenizer，同步设置。
- `L117-L120`：若底层 auto_model config 没有 `pad_token_id`，补上。
- `L121`：返回可用的模型对象。

---

## 2) `experiments/build_triplets.py` 逐行注释

- `L1`：延迟类型注解解析。
- `L3-L5`：导入参数解析、默认字典、类型声明。
- `L7`：导入 HuggingFace `datasets` 的加载接口。
- `L9`：导入项目通用工具。
- `L12`：定义构建 triplet 的核心函数。
- `L13`：读取指定数据集和 split（默认 SNLI）。
- `L14`：按 `premise -> label -> hypotheses` 组织样本。
- `L15`：初始化 triplets 列表。
- `L17`：遍历数据集每行。
- `L18`：读取标签，缺失时用 -1。
- `L19-L20`：只保留 0（entailment）和 2（contradiction）。
- `L21-L22`：读取并清洗 premise/hypothesis。
- `L23-L24`：空文本直接跳过。
- `L25`：把 hypothesis 挂到同 premise 的对应标签桶里。
- `L27`：当同一 premise 同时有 0 和 2，就可组 triplet。
- `L28-L34`：写入一个 triplet（query/positive/hard_negative）。
- `L35`：移除该 premise，避免重复组装。
- `L36-L37`：达到上限则停止。
- `L38`：返回 triplets。
- `L41`：定义烟雾测试集构造函数。
- `L42-L70`：直接返回 3 条手工 query（否定/排除/数值）及文档和 satisfies 标签。
- `L73`：把 smoke 数据展平成去重语料。
- `L74`：初始化结果列表。
- `L75`：初始化去重集合。
- `L76-L77`：遍历每个 query 的 docs。
- `L78`：取文档文本。
- `L79-L80`：已出现文本跳过。
- `L81`：记录该文本已见。
- `L82`：生成 `doc-{idx}` 并写入语料。
- `L83`：返回语料列表。
- `L86`：定义命令行参数。
- `L87`：创建参数解析器。
- `L88-L93`：定义数据集名、split、样本上限、随机种子参数。
- `L94`：返回解析结果。
- `L97`：主函数入口。
- `L98`：读取参数。
- `L99`：确保目录存在。
- `L100`：固定随机种子。
- `L102-L103`：分别构建 train/val triplets。
- `L105-L106`：定义 train/val 输出路径。
- `L107-L108`：写出 train/val jsonl。
- `L110`：构建 smoke eval 数据。
- `L111`：定义 smoke 输出路径。
- `L112`：写出 smoke jsonl。
- `L114`：从 smoke 构建 demo 语料。
- `L115`：定义语料输出路径。
- `L116`：写出语料 jsonl。
- `L118-L121`：打印各文件产出数量与路径。
- `L124-L125`：脚本方式运行时执行 `main()`。

---

## 3) `experiments/train_constraint_encoder.py` 逐行注释

- `L1`：延迟类型注解解析。
- `L3-L4`：导入参数解析与路径库。
- `L6`：导入 sentence-transformers 的训练组件。
- `L7`：导入 PyTorch DataLoader。
- `L9`：导入项目通用函数和路径。
- `L12`：定义参数解析函数。
- `L13`：创建训练脚本说明。
- `L14-L20`：定义训练文件、base model、输出目录、epoch、batch、最大长度、seed。
- `L21`：返回参数对象。
- `L24`：把 json 行转换为 `InputExample`。
- `L25`：初始化样本列表。
- `L26`：遍历每行训练样本。
- `L27-L29`：读取并清洗 query/positive/negative。
- `L30`：三者都非空才用。
- `L31`：写入三塔格式 `texts=[q,p,n]`。
- `L32`：返回样本列表。
- `L35`：主流程入口。
- `L36`：解析参数。
- `L37`：创建目录。
- `L38`：设随机种子。
- `L40`：读取训练 jsonl。
- `L41`：转 `InputExample`。
- `L42-L43`：无有效样本则报错退出。
- `L45`：构建 Transformer 编码层，设置最大序列长度。
- `L46`：构建池化层（将 token 表示聚合为句向量）。
- `L47`：组装 SentenceTransformer 模型。
- `L49`：构建 DataLoader，打乱并按 batch 训练。
- `L50`：定义损失函数 `MultipleNegativesRankingLoss`。
- `L52`：warmup 步数设为总步数的 10%。
- `L53-L59`：调用 `model.fit()` 开始训练并保存模型。
- `L61`：打印训练完成和模型路径。
- `L64-L65`：脚本执行入口。

---

## 4) `experiments/retrieve_then_filter.py` 逐行注释

- `L1`：延迟注解解析。
- `L3-L4`：导入参数与路径。
- `L6`：导入 `numpy`。
- `L8`：导入项目公共函数。
- `L11`：定义命令行参数。
- `L12`：脚本说明：先 topic 召回，再 constraint 重排/过滤。
- `L13`：输入查询（必填）。
- `L14`：语料文件路径。
- `L15`：topic 模型名或路径。
- `L16`：constraint 模型路径。
- `L17`：初召回候选数。
- `L18`：最终返回条数。
- `L19`：融合权重 alpha。
- `L20`：可选阈值 tau（默认不启用过滤）。
- `L21`：返回参数对象。
- `L24`：定义向量检索打分函数。
- `L25`：编码 query（归一化）。
- `L26`：编码 docs（归一化）。
- `L27`：文档向量与 query 向量点积（等价 cosine）。
- `L30`：主流程。
- `L31`：读取参数。
- `L32`：读取语料 JSONL。
- `L33-L34`：语料为空报错并提示先跑数据构建。
- `L36`：抽取文档文本数组。
- `L37`：抽取文档 id，缺失则自动补 `doc-i`。
- `L39`：加载 topic 模型。
- `L40`：计算 topic 分数。
- `L42`：按 topic 分降序取前 `top-k-retrieve`。
- `L43-L45`：取候选文档、候选 id、候选 topic 分。
- `L47`：加载 constraint 模型。
- `L48`：计算候选上的 constraint 分。
- `L50`：如果传了 `tau`，进入过滤分支。
- `L51`：布尔掩码：分数是否 >= tau。
- `L52-L55`：同步过滤 docs/id/topic/constraint 四个数组。
- `L57`：融合打分（alpha 加权）。
- `L58`：按融合分排序，取前 `top-k-final`。
- `L60-L61`：打印 query 和结果标题。
- `L62-L65`：逐条打印排序位置、各项分数、文档文本。
- `L68-L69`：脚本执行入口。

---

## 5) `experiments/eval_retrieval_metrics.py` 逐行注释

- `L1`：延迟注解解析。
- `L3-L6`：导入参数、json、默认字典、路径。
- `L8`：导入 `numpy`。
- `L10`：导入公共函数（读数据、加载模型、目录等）。
- `L11`：导入指标函数（Recall/NDCG/CCR）。
- `L14`：定义参数解析。
- `L15`：脚本说明：比较 vanilla 与 dual 的多指标表现。
- `L16-L20`：benchmark 文件参数（query 侧标签）。
- `L21-L25`：corpus 文件参数（doc_id + text）。
- `L26`：topic 模型参数。
- `L27`：constraint 模型参数。
- `L28`：初召回深度 `retrieve-k`。
- `L29`：最终关注的 top-k（报告里实际以 top10/top100 为主）。
- `L30`：融合权重。
- `L31`：约束阈值。
- `L32-L36`：输出报告路径。
- `L37`：返回参数对象。
- `L40`：定义均值工具函数。
- `L41`：有值返回均值，无值返回 0。
- `L44`：主流程开始。
- `L45`：解析参数。
- `L46`：确保目录存在。
- `L48-L49`：读取 benchmark 与 corpus。
- `L50-L53`：为空则报错退出。
- `L55`：取所有文档 id 列表。
- `L56`：取所有文档文本列表。
- `L58-L59`：加载 topic/constraint 模型。
- `L61`：一次性编码全语料 topic 向量（提高效率）。
- `L62-L64`：一次性编码全语料 constraint 向量。
- `L66`：初始化每 query 报告容器。
- `L67-L69`：初始化按类别统计容器。
- `L70`：初始化 overall 聚合容器。
- `L72`：遍历每个 query 样本。
- `L73-L77`：读取 query、category、relevant 集合、约束满足集合、graded relevance。
- `L79-L80`：分别编码 query 的 topic 向量和 constraint 向量。
- `L82-L83`：与语料向量点积，得到两种分数。
- `L85`：vanilla 全量排序索引（topic 降序）。
- `L86`：映射为 `doc_id` 序列。
- `L88`：先取 vanilla 前 `retrieve-k` 作为 dual 候选池。
- `L89`：候选池内做融合分。
- `L90`：保留 constraint 分数 >= tau 的候选。
- `L91-L95`：若有保留文档，按融合分再排序得到 dual 候选排名。
- `L96-L97`：若全部被过滤，回退到 retrieve_idx（避免空结果）。
- `L98`：构造 dual 全量排名：`dual候选 + 其余vanilla文档`。
- `L100-L101`：截取 vanilla/dual 的 top10 doc id。
- `L102-L121`：计算并组装当前 query 的所有指标与 top10 列表。
- `L122`：写入 per_query。
- `L124`：遍历两种模式统计汇总。
- `L125-L127`：把每个指标值累积到 overall 和按类别容器。
- `L129`：准备按类别聚合输出。
- `L130-L148`：逐类别计算 vanilla/dual 的均值指标并写入结构。
- `L150`：组装最终报告对象。
- `L151-L158`：记录输入配置（文件、模型、参数）。
- `L159-L172`：overall 均值结果（vanilla vs dual）。
- `L173-L178`：绝对提升值（dual - vanilla）。
- `L179-L180`：加入按类别和逐 query 明细。
- `L183`：准备输出路径。
- `L184`：保证输出目录存在。
- `L185`：写 JSON 报告。
- `L186-L187`：打印 overall 和 improvement 方便终端快速查看。
- `L188`：打印报告落盘路径。
- `L191-L192`：脚本执行入口。

---

## 6) `experiments/rag_grid_search.py` 逐行注释

- `L1`：延迟注解解析。
- `L3-L6`：导入参数、json、随机抽样、路径。
- `L8`：导入 `numpy`。
- `L10`：导入公共函数。
- `L13`：定义网格字符串解析函数。
- `L14`：按逗号切分并去空白。
- `L15`：按 `cast` 转类型（默认 float）。
- `L18`：定义通用打分函数。
- `L19-L20`：编码 query 和 docs。
- `L21`：返回 dot-product 分数数组。
- `L24`：定义 CCR@k。
- `L25-L28`：取前 k 并计算满足约束比例。
- `L31`：主函数开始。
- `L32`：脚本说明（alpha/tau 网格搜索）。
- `L33-L42`：定义 eval 文件、模型、参数网格、top-k、采样数、seed、输出路径。
- `L42`：解析参数。
- `L44`：保证目录存在。
- `L45`：读取评测数据。
- `L46-L47`：空文件报错退出。
- `L48-L50`：如果设置 `max_queries`，随机采样子集加速实验。
- `L52-L53`：把 alpha/tau 参数字符串转成列表。
- `L55-L56`：加载 topic 与 constraint 模型。
- `L58`：初始化缓存容器 `prepared`。
- `L59-L65`：预计算每个 query 的 topic 分、constraint 分和标签，避免网格循环重复编码。
- `L67`：保存所有参数组合结果。
- `L68`：保存当前最优配置。
- `L69-L70`：双层循环遍历 `(alpha, tau)`。
- `L71`：当前配置的 per-query 结果容器。
- `L72`：遍历缓存后的每个 query。
- `L73`：取标签数组。
- `L74`：按 alpha 融合分数。
- `L76`：按 tau 过滤 constraint 分不达标文档。
- `L77-L78`：有保留则按融合分降序排序。
- `L79-L80`：若全被过滤，回退 topic 排序。
- `L82`：计算当前 query 的 CCR@k。
- `L83`：记录当前 query CCR。
- `L85`：求当前参数组平均 CCR。
- `L86`：组装当前参数组结果行。
- `L87`：加入总结果。
- `L88-L89`：更新最优参数（更高 avg_ccr）。
- `L91`：开始计算 vanilla 基线。
- `L92-L94`：每个 query 用纯 topic 排序算 CCR@k。
- `L95`：求 vanilla 平均 CCR。
- `L97-L109`：组装最终报告（包含 best、improvement、全部结果排序）。
- `L111`：输出路径对象。
- `L112`：保证目录存在。
- `L113`：写 JSON 报告。
- `L115`：打印 vanilla 平均 CCR。
- `L116-L120`：若 best 存在，打印最优 alpha/tau 和提升。
- `L121`：打印输出文件路径。
- `L124-L125`：脚本执行入口。

---

## 7) 你怎么用这份“逐行版”

- 打开一个脚本后，按本文件对应章节逐条对照 `Lx` 看。
- 看不懂的地方先只抓“输入是什么 -> 做了什么变换 -> 输出到哪里”。
- 建议先把第 4、5、6 节（检索和评估）看懂，再回头看训练细节。

如果你要，我可以继续补第二卷，把剩下 13 个脚本也做成同样的逐行注释（保持同一格式）。

