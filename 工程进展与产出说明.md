# Constraint-Aware RAG 工程进展与产出说明

## 1. 项目目标（截至当前）

围绕 `RAG` 中“相关但违约束”的检索错误（hard negatives），实现并验证一个可插拔的双视角检索框架：

- `Encoder A`：负责 topic relevance（召回）
- `Encoder B`：负责 constraint compliance（过滤/重排）
- 在线流程：`Retrieve -> Constraint Filter/Rerank -> Generate`

核心评价指标为 `CCR@k`（Constraint Compliance Rate）。

---

## 2. 已完成的工程实现

### 2.1 项目基础结构

已建立可运行工程骨架：

- `experiments/`：训练与评估脚本
- `data/processed/`：数据与基准集
- `outputs/checkpoints/`：模型产物
- `outputs/reports/`：实验报告
- `outputs/figures/`：图像结果

### 2.2 核心脚本

1. `experiments/common.py`  
   - 路径管理、jsonl 读写、指标计算、编码器加载工具。

2. `experiments/build_triplets.py`  
   - 从 SNLI 构建训练/验证 triplets（query/positive/hard_negative）。  
   - 同时生成 smoke eval 与 demo corpus。

3. `experiments/poc_negation_gap.py`  
   - PoC：检测 embedding 在 contradiction 场景下的相似度分布。

4. `experiments/train_constraint_encoder.py`  
   - 训练 `Constraint Encoder`（已产出 `constraint-encoder-v1`）。

5. `experiments/eval_constraint_encoder.py`  
   - triplet 层面离线评估（pairwise accuracy / margin）。

6. `experiments/retrieve_then_filter.py`  
   - 在线检索链路演示：召回 + 约束重排/过滤。

7. `experiments/rag_eval.py`  
   - 在评测集上计算 vanilla vs dual 的 CCR。

8. `experiments/rag_grid_search.py`  
   - `alpha/tau` 网格搜索，自动找最优配置。

9. `experiments/build_constraint_benchmark.py`  
   - 构建第三轮大规模约束基准（negation/exclusion/numeric）。

10. `experiments/rag_category_report.py`  
    - 分类别输出 CCR 对比（论文分析用）。

11. `experiments/render_category_table.py`  
    - 将类别报告渲染成可直接贴论文的 Markdown 表格。

### 2.3 兼容性改造

- 已支持本地模型路径（如 `/data/xingkun/local_model/Llama-3.2-3B-Instruct`）作为 topic 模型。
- 修复了本地因果模型常见问题：`tokenizer` 缺失 `pad_token` 导致编码失败；现已自动回退设置。

---

## 3. 数据与模型产物

### 3.1 数据文件

- `data/processed/train_triplets.jsonl`
- `data/processed/val_triplets.jsonl`
- `data/processed/smoke_eval.jsonl`
- `data/processed/demo_corpus.jsonl`
- `data/processed/constraint_benchmark_v1.jsonl`（第三轮，300 queries）

### 3.2 模型文件

- `outputs/checkpoints/constraint-encoder-v1/`
  - 包含 `model.safetensors` 和完整 tokenizer/config。

### 3.3 报告文件（核心）

- `outputs/reports/poc_negation_gap_summary.txt`
- `outputs/reports/constraint_eval_report.json`
- `outputs/reports/rag_grid_search_minilm.json`
- `outputs/reports/rag_grid_search_local_llama.json`
- `outputs/reports/rag_grid_search_v1_minilm_300.json`
- `outputs/reports/rag_grid_search_v1_local_llama_60.json`
- `outputs/reports/rag_category_report_minilm_300.json`
- `outputs/reports/rag_category_report_local_llama_60.json`
- `outputs/reports/rag_category_tables_round3.md`

---

## 4. 实验进展（分轮次）

## 第一轮：跑通闭环 + 初步验证

完成内容：

- 数据构建、训练、离线评估、在线评估链路全部打通。
- 训练并产出第一版 `Constraint Encoder`。

关键结果：

- PoC（MiniLM, 800 samples）
  - entailment sim: `0.6616`
  - contradiction sim: `0.3276`
  - pairwise acc: `0.9463`
- Constraint Encoder 离线提升（800 triplets）
  - baseline acc: `0.94625`
  - constraint acc: `0.96500`
  - `+0.01875`（绝对提升）

结论：

- Encoder B 在“区分正负约束样本”上有效。

## 第二轮：小集参数搜索（smoke）

完成内容：

- 执行 `alpha/tau` 网格搜索，分别在 MiniLM topic 与本地 Llama topic 上验证。

关键结果：

- MiniLM（smoke）
  - vanilla CCR@3: `0.4444`
  - best: `alpha=0.0, tau=0.6, CCR=0.5556`
  - improvement: `+0.1111`
- 本地 Llama（smoke）
  - vanilla CCR@3: `0.6667`
  - best dual 无提升（`alpha=1.0, tau=-1.0`，等价 vanilla）

结论：

- 小样本不稳定，需扩充评测集。

## 第三轮：扩充基准（300 queries）+ 重跑网格

完成内容：

- 构建 `constraint_benchmark_v1`：negation/exclusion/numeric 各 100。
- 在更大数据上重新做网格搜索。

关键结果：

- MiniLM（300）
  - vanilla CCR@3: `0.4767`
  - best dual: `alpha=0.0, tau=0.6, CCR=0.5728`
  - improvement: `+0.0961`
- 本地 Llama（60 子集）
  - vanilla CCR@3: `0.4056`
  - best dual: `alpha=0.0, tau=0.6, CCR=0.5750`
  - improvement: `+0.1694`

结论：

- 最优模式趋于稳定：`低 alpha + 高 tau`（更强调 constraint 过滤）。

## 第四轮：分类型分析（论文可用）

配置固定：`alpha=0.0, tau=0.6, top-k=3`

MiniLM（300）：

- overall: `47.67% -> 57.28%`（`+9.61%`）
- exclusion: `54.33% -> 60.50%`（`+6.17%`）
- negation: `22.00% -> 22.00%`（`+0.00%`）
- numeric: `66.67% -> 89.33%`（`+22.67%`）

本地 Llama（60）：

- overall: `40.56% -> 57.50%`（`+16.94%`）
- exclusion: `45.83% -> 60.42%`（`+14.58%`）
- negation: `10.53% -> 21.05%`（`+10.53%`）
- numeric: `66.67% -> 94.12%`（`+27.45%`）

结论：

- 提升主要来自 `numeric` 与 `exclusion`。
- `negation` 仍是当前最薄弱类型（尤其 MiniLM 上）。

---

## 5. 当前可支撑的论文论断

1. Dual-view 检索在约束遵循上有明确增益（CCR 提升可复现）。
2. 最优策略并非“topic + constraint 平衡”，而是强约束过滤优先（本实验分布下）。
3. 模型收益具有类型差异：numeric > exclusion > negation。
4. 该方案可以作为向量检索后、生成前的轻量防线。

---

## 6. 当前限制与风险

1. 主要评测集仍是模板合成，真实用户分布不足。
2. negation 处理提升不稳定，说明训练样本和任务定义还不够针对。
3. 本地大模型评估用了子集（60），不是全量。
4. 还缺少端到端生成质量（faithfulness/hallucination）大规模实证。

---

## 7. 下一步建议（直接可执行）

1. **做 negation 专项数据增强**
   - 强化 scope（`not A but B`、双重否定、跨子句否定）。
2. **扩展真实查询评测集**
   - 至少 300~1000 条人工标注约束 query。
3. **补端到端 RAG 实验**
   - 报告回答正确率/faithfulness 与延迟。
4. **补强对比基线**
   - 引入 cross-encoder reranker 质量-延迟对比。
5. **整理投稿材料**
   - 固定主结果表、消融表、误例分析图，映射到 EMNLP 章节结构。

---

## 8. 相关论文草稿与文档

- `EMNLP_Constraint_Aware_RAG_Draft.md`（已生成英文论文草稿）
- `想法整理/RAG方向.md`（项目方案文档）
- `readme.md`（运行与复现实验说明）

